{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Q. 在编译模型阶段，定义了多输出loss函数和权重，但在训练阶段，打印的loss却不等于各个loss的加权和\n",
    "```\n",
    "model.compile(loss=my_loss, optimizer='adam', loss_weights=[0.5, 0.5])\n",
    "model.fit(dataset, epochs=2, steps_per_epoch=2, verbose=1)\n",
    "```\n",
    "输出：loss(21.9610) != 0.5 * 1.3583 - 0.5 * 1.5867\n",
    "```\n",
    "Epoch 1/2\n",
    "1/2 [==============>...............] - ETA: 0s - loss: 21.9610 - dense_4_loss: 1.3583 - dense_5_loss: 1.5867\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "2/2 [==============================] - 0s 140ms/step - loss: 22.1960 - dense_4_loss: 1.9502 - dense_5_loss: 1.5183\n",
    "Epoch 2/2\n",
    "1/2 [==============>...............] - ETA: 0s - loss: 21.8526 - dense_4_loss: 1.3555 - dense_5_loss: 1.5861\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "2/2 [==============================] - 0s 1ms/step - loss: 22.0872 - dense_4_loss: 1.9470 - dense_5_loss: 1.5171\n",
    "```\n",
    "\n",
    "\n",
    "**Answer**: 因为总的loss中包含了权重正则化损失部分：\n",
    "```\n",
    "def build_net(input_tensor):\n",
    "    out1 = keras.layers.Dense(1, kernel_initializer='glorot_normal', activation='linear',\n",
    "                              kernel_regularizer=keras.regularizers.l2(10))(input_tensor)\n",
    "    out2 = keras.layers.Dense(1, kernel_initializer='glorot_normal', activation='linear',\n",
    "                              kernel_regularizer=keras.regularizers.l2(10))(input_tensor)\n",
    "    return [out1, out2]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q. 在将`.ckpt.index` + `.ckpt.data` 模型转为`pb`的时候，为什么还要先保存为`h5`，然后再加载模型，再保存为`pb`？\n",
    "\n",
    "\n",
    "**Answer**: 因为原来保存为`.ckpt.index` + `.ckpt.data` 的时候没有保存图信息，加载也只加载权重信息：\n",
    "```\n",
    "model.load_weights(latest)\n",
    "...\n",
    "cp_callback = ModelCheckpoint(path, save_weights_only=True, period=ckpt_period)\n",
    "```\n",
    "导致`keras.backend.get_session().graph.as_graph_def()`没有图结构信息。\n",
    "（理论上我是构建了网络图模型，然后再加载权重的，所以应该也得有图结构信息，但实际上没有）\n",
    "所以需要将模型完全保存为`h5`（包含图信息），然后重新加载进来，再保存为`pb`：\n",
    "```\n",
    "model.save(h5_path, overwrite=True, include_optimizer=False)\n",
    "model = keras.models.load_model(h5_path)\n",
    "...\n",
    "graph = tf.graph_util.remove_training_nodes(sess.graph.as_graph_def())\n",
    "graph_frozen = tf.graph_util.convert_variables_to_constants(sess, graph, output_names)\n",
    "tf.train.write_graph(graph_frozen, pb_model_dir, pb_model_name, as_text=False)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q. 一直没办法用多GPU的模式运行？\n",
    "\n",
    "\n",
    "**Answer**: `tf.enable_eager_execution()`模型跑不了多GPU，要注释掉这句。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q. Jupyter Notebook运行tf.keras.Model对象训练、预测，在model.predict()时报错`CancelledError:  [Op:StatefulPartitionedCall]`？\n",
    "\n",
    "**Answer**：不清楚为什么，但是如果选择 `Kernel -> Restart & Run All` 则能得到正确的结果。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q. TensorFlow自定义层有bug太难调了！！！\n",
    "\n",
    "\n",
    "**Answer**：目前我调试就只有几个操作：\n",
    "- tf.print() + with tf.control_dependencies()，打印信息；\n",
    "- with tf.name_scope('name')，给操作加名称，定位到出错的局部操作；\n",
    "- tf_debug.has_inf_or_nan，或自定义只有inf/nan，查看出现inf和nan的位置；\n",
    "- with tf.GradientTape(persistent=persistent) as tape，详细查看梯度。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
